{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Objective:\n",
        "\n",
        "\n",
        "*   Clean facility name (remove special characters, capitalize letters, convert roman numerals ...)\n",
        "*   Correct misspelling with help of spelling dictionary\n",
        "*   Separate facility name and facility type into separate columns with help of type dictionary\n",
        "*   Create facility sub-types\n",
        "\n",
        "\n",
        "\n",
        "#Process\n",
        "\n",
        "\n",
        "### Step 1: \n",
        "Make a copy of this script and add the name of your country to the file name, e.g. preprocessing_MOZ. Then, run this notebook on your health facility datasets. Doing so will add the following columns to your health facility datasets:\n",
        "* **facility_name_short**: Cleaned facility names without a type. An example entry is 'Columbia,' which has been converted from 'columbia hospital.'\n",
        "* **extract_type** :These are raw facility types extracted from **facility_name** column. \n",
        "* **sub_type** : Formatted and aggregated facility type from **extract_type** column. The type dictionary is going to be used as reference facility types. In some countries, some facilities are written as District Hospital, and some of them as Hospital District. The **extract_type** column is going to hold both types, but in **sub_type** we will just keep District Hospital (based on type dictionary) as it is but reformat Hospital District as District Hospital.\n",
        "* **score** : We are using a fuzzy match method to aggregate and format facility types from the **extract_type** column. This column shows the match score, which is a number 100-0. 100 indicates a perfect match, and 0 indicates that the values are totally different. \n",
        "* **hf_name_length** : Length of facility name. \n",
        "* **hf_type_length** :  Length of facility type. \n",
        "* **special_chrs** : List of special characters that a facility name includes such as !?\\/`\"&* \n",
        "* **only_numerical** : Facility names that consist of only numerical values\n",
        "\n",
        "\n",
        "\n",
        "### Step 2:\n",
        "\n",
        "* **Go through each facility type in the sub_type column that has a score lower than 75**. We want to make sure we  aggregate facility types in the right way. A score lower than 75 can be misclassified. Correct the cases that you find missclassified in the **sub_type** column.\n",
        "* **Check facilities without a type**. Some of the facilites do not have a type. For those facilities, the **sub_type** column should be empty. For these cases, check the **facility_name_short** column and confirm facility name does not include a type. If you find that facility name includes its type, manually exclude facility type from facility name in **facility_name_short** column and move facility type to **sub_type** column. \n",
        "* **Check facilities without a name**. Some of the facilities do not have a name. For those cases **facility_name_short** should be empty. If it's empty, check **facility_name** column and confirm that the facility name does not include a name (just type). If you find that, in the **facility_name** column, a facility name exists, manually enter facility name into **facility_name_short** column.\n",
        "* **Check very long or short facility name**. Some facility names are very long or short. Sometimes that's an indication that the name is wrong, so we need to manually check. Please go over facility names in *facility_name_short* column  that have over 30 characters and less than 3 characters. You can sort text by length in Excel. Correct facility name in **facility_name_short** column if you think they are misspelled. \n",
        "* **Check very long or short facility types**: Some of the facility types are very long or short.  Please go over facility types in **sub_type** that have over 20 characters and fewer than 3 characters. Correct facility type at **sub_type**  if you think they are misspelled. \n",
        "* **Check facility names that have a special characters**.Facility names that have special characters have been palced in a  **special_chrs** column.Some of these characters are not right.Remove the characters  at **facility_name_short** column  that are listed **special_chrs** column  that you think wrong.\n",
        "* **Check facility names that consist of only numerical characters**. These facilities are flagged in an **only_numerical** column. For these cases, check **facility_name**  column name, and confirm that facility name consists of only numerical values. If not, correct the facility name in the **facility_name_short** column.\n",
        "\n",
        "\n",
        "\n",
        "### Step 3:\n",
        "\n",
        "* Repeat steps 1 and 2 for each health facility dataset you have explored in previous landscaping exercises. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "L5j23M1Uc-uN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1 : Import Modules\n"
      ],
      "metadata": {
        "id": "DP9sugSQwq6B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The cell below imports some modules that are not existent in python's default enviroment. You need to run the cell below to import external modules into the notebook environment. Just run the cell without modifying it. Run the cell by hovering over the cell and clicking the icon in the top left. When it is finished, a green checkmark will appear to the left of the cell."
      ],
      "metadata": {
        "id": "dKpkmNV6sXnI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Ordered_set\n",
        "!pip install thefuzz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unuX-RaesUNG",
        "outputId": "2e41b991-73f2-499a-b3fa-ac5c2a023b65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Ordered_set in /usr/local/lib/python3.7/dist-packages (4.1.0)\n",
            "Requirement already satisfied: thefuzz in /usr/local/lib/python3.7/dist-packages (0.19.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The cell below imports required modules. Just run the cell without modifying it. It does not create any output. It runs very fast. \n"
      ],
      "metadata": {
        "id": "NeySdVNJenC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "import io\n",
        "from ordered_set import OrderedSet\n",
        "from thefuzz import process, fuzz\n",
        "\n"
      ],
      "metadata": {
        "id": "DkFQNLoVcphu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: Provide required inputs"
      ],
      "metadata": {
        "id": "y5cNyZv0w9cS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The cell below requires some inputs from you. Please provide required inputs as explained below and then click the run icon on the top left of the cell:\n",
        "\n",
        "\n",
        "*   **country name** : Name of country (either iso code or full name)\n",
        "*   **health_facility_table**: Table name for which you want to create a facility type table. For our case it is one of the health facility datasets you've explored previously. Ideally you should use the HF dataset that you modified with standardized column names. The table file format should be csv or xlsx\n",
        "\n",
        "* **facility_name**: Column name in the input table (aka health facility dataset) for the column that has facility name. If using the HF dataset version that you modified with column name standardization, you would put \"facility_name\" here\n",
        "\n",
        "*   **type_dictionary_table**: type dictionary table that you created from the previous python exercise\n",
        "\n",
        "*   **spelling_dictionary_table**: spelling dictionary table that you created from the previous python exercise\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Oj6jD_ZBga0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "country_name=\"NGA\"\n",
        "health_facility_table=\"eHealth_HFL_OpenAfrica_modified.xlsx\"\n",
        "facility_name=\"facility_name\"\n",
        "spelling_dictionary_table=\"merged_spelling_dictionary_v3.xlsx\"\n",
        "type_dictionary_table=\"Merged_type_dictionary_v3.xlsx\"\n"
      ],
      "metadata": {
        "id": "IryaZ-Q8ckHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3: Upload input table"
      ],
      "metadata": {
        "id": "6Nl01tGYxjVr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The cell below allows you to choose the input table from your computer. After you run the cell below, you should see a **choose files** option. Click on the **choose files** option and then navigate your computer to find the files you want to read as **health_facility_table** (aka the health facility dataset) and **spelling_dictionary_table** and **type_dictionary_table**  from a previous exercise. You need to choose all files at the same time. It may take some time for Python to read a table based on file size and speed of your internet connection.\n",
        " \n"
      ],
      "metadata": {
        "id": "cS5oWhC6ip-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded=files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "K4-cHe6xc6FX",
        "outputId": "4d983d85-944c-4b35-fcc0-6de5f1bff717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-92520eac-ed32-4554-a8fd-4b11f32f4c2e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-92520eac-ed32-4554-a8fd-4b11f32f4c2e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving eHealth_HFL_OpenAfrica_modified.csv to eHealth_HFL_OpenAfrica_modified (1).csv\n",
            "Saving merged_spelling_dictionary_v3.xlsx to merged_spelling_dictionary_v3 (2).xlsx\n",
            "Saving Merged_type_dictionary_v3.xlsx to Merged_type_dictionary_v3 (2).xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part 4: Create word frequency table"
      ],
      "metadata": {
        "id": "EmOq-aNOxwme"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the cell below. No need for any modification. After processing is done, you should see a csv file downloaded to your computer. The file is going to be saved in your **downloads** directory. The output table will have the same name as the health facility dataset with cleaned at the end. For example, if the input table name is DRC_health_facility, the output table name is going to be DRC_health_facility_cleaned. It may take some time. Please wait until the process is fully complete."
      ],
      "metadata": {
        "id": "gb8NkV48mVu6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preclean(df, input_variable, output_variable, remove_accent=False):\n",
        "  '''\n",
        "    Basic cleaning and standardization of a column\n",
        "    :param df: dataframe\n",
        "    :param input_variable: a column name to be cleaned/standardized\n",
        "    :param output_variable: cleaned/standardized column name\n",
        "    :param remove_accent:remove french characters\n",
        "    :return: dataframe\n",
        "  '''\n",
        "    ##=============================================================================#\n",
        "  df[output_variable] = df[input_variable] + \" \"\n",
        "  # replace NAs with empty string ''\n",
        "  df[output_variable] = df[output_variable].fillna('')\n",
        "  # remove accent marks\n",
        "  if remove_accent:\n",
        "      df[output_variable] = [unidecode.unidecode(n) for n in df[output_variable]]\n",
        "  df[output_variable] = df[output_variable] \\\n",
        "      .str.replace(\" III | Iii  | iii \", \" 3 \") \\\n",
        "      .str.replace(\" II | Ii  | ii \", \" 2 \") \\\n",
        "      .str.replace(\" I | i \", \" 1 \") \\\n",
        "      .str.replace(\" IV | Iv | iv \", \" 4 \") \\\n",
        "      .str.replace('&', 'and')\n",
        "  df[output_variable] = df[output_variable].apply(lambda x: \" \".join(re.split('(\\d+)', x)))\n",
        "  df[output_variable] = df[output_variable].map(lambda x: re.sub(r'[#$%&*+,-./:;<=>?@[\\]^_`{|}~]', ' ', x)).str.strip().str.replace(\"  \",\" \")\n",
        "  df[output_variable] = df[output_variable].str.title(). \\\n",
        "      str.replace(r'\\s+', ' ').str.strip()\n",
        "  # replace NAs in output_variable with empty string ''\n",
        "  df[output_variable] = df[output_variable].fillna(' ')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def correct_spelling(df, spelling_dict, clean_name, output_col):\n",
        "    '''\n",
        "    Makes correction to possible misspellings using the spelling dictionary\n",
        "    :param df: dataframe\n",
        "    :param spelling_dict: csv file with correct spelling dictionary\n",
        "    :param clean_name:cleaned/standardized column name\n",
        "    :param output_col:A column name to hold corrected names\n",
        "    :param spelling_dict: Country specific spelling dictionary\n",
        "    :return:dataframe\n",
        "    '''\n",
        "\n",
        "\n",
        "    words_to_correct = spelling_dict['word'].unique()\n",
        "\n",
        "    df[output_col] = df[clean_name]\n",
        "    for word in words_to_correct:\n",
        "        misspellings = list(spelling_dict[(spelling_dict['word'] == word)]['misspelling'])\n",
        "        for misspelling in misspellings:\n",
        "            df[output_col] = df[output_col] \\\n",
        "                .str.replace('|'.join(['^' + misspelling + ' ', ' ' + misspelling + ' ',\n",
        "                                       ' ' + misspelling + '$', '^' + misspelling + '$']), ' ' + word + ' ',\n",
        "                             case=False) \\\n",
        "                .str.strip().replace(\" De \", \" de \")\n",
        "\n",
        "\n",
        "    # reset and drop index\n",
        "    df.reset_index(inplace=True, drop=True)\n",
        "\n",
        "\n",
        "def remove_type_info(df, type_dict, clean_name, clean_name_final):\n",
        "    \"\"\"\n",
        "    Use facility type and abbreviations in the type dictionary as keywords and remove type information\n",
        "    :param df: dataframe\n",
        "    :param type_dict: Country specific type dictionary as csv file\n",
        "    :param clean_name: Cleaned/standardized name column\n",
        "    :param clean_name_final: Output column to keep name without a type\n",
        "    :return: dataframe\n",
        "    \"\"\"\n",
        "    # remove whitespace between abbreviations of length 2 or 3\n",
        "    # e.g. change C S to CS\n",
        "\n",
        "    # obtain abbreviations of length 2 or 3\n",
        "    type_dict['abbreviation'].fillna(type_dict['type'], inplace=True)\n",
        "    tmp = type_dict[type_dict['abbreviation'].str.len() <= 4]['abbreviation'].unique()\n",
        "    # sort by decreasing length\n",
        "    tmp = sorted(tmp, key=len, reverse=True)\n",
        "    # change it to the pattern '^c s ' or ' c s$'\n",
        "    tmp_dict = {}\n",
        "    for t in tmp:\n",
        "        tmp_dict[t] = ['^' + ' '.join(list(t)) + ' ', ' ' + ' '.join(list(t)) + '$']\n",
        "    # replace the pattern with 'cs'\n",
        "    for t in tmp:\n",
        "        pats = tmp_dict[t]\n",
        "        df[clean_name] = df[clean_name].str.replace(pats[0], t + ' ', case=False) \\\n",
        "            .str.replace(pats[1], ' ' + t, case=False)\n",
        "\n",
        "    # facility types\n",
        "    types = list(type_dict['type'])\n",
        "    type_keywords = set()\n",
        "    for t in types:\n",
        "        # add the full facility type\n",
        "        t = t.title()\n",
        "        type_keywords.add(t)\n",
        "\n",
        "        # add individual words as well\n",
        "        t = t.replace('/', ' ')\n",
        "        words = t.split(' ')\n",
        "        # skip words that have punctuation / numbers and have length <= 3 (e.g. de, (major))\n",
        "        words = [w for w in words if w.isalpha() and len(w) > 3]\n",
        "        for w in words:\n",
        "            type_keywords.add(w)\n",
        "\n",
        "    # obtain the list of type keywords and sort in descending length\n",
        "    type_keywords = list(type_keywords)\n",
        "    type_keywords = sorted(type_keywords, key=lambda s: -len(s))\n",
        "\n",
        "    # abbreviations for that country\n",
        "    abbrevs = set(type_dict['abbreviation'])\n",
        "\n",
        "    abb_keywords = []\n",
        "    for abbrev in abbrevs:\n",
        "        # e.g. for CS, 4 patterns are considered: '^CS ', ' CS ', ' CS$', '^CS$'\n",
        "        abbrev = abbrev.title()\n",
        "        abb_keywords.extend(['^' + abbrev + '\\s', '\\s' + abbrev + '\\s', '\\s' + abbrev + '$',\n",
        "                             '^' + abbrev + '$'])\n",
        "\n",
        "    # obtain the list of abbreviation keywords and sort in descending length\n",
        "    abb_keywords = sorted(abb_keywords, key=lambda s: -len(s))\n",
        "\n",
        "    # handle situations when type is 'Hospital District' in the type dictionary\n",
        "    # but name column has 'District Hospital' in ISS data\n",
        "    type_len_2 = [t for t in type_keywords if len(t.split()) == 2]\n",
        "    for t in type_len_2:\n",
        "        df[clean_name] = df[clean_name].str.title() \\\n",
        "            .str.replace(' '.join(t.split()[::-1]), t, case=False)\n",
        "\n",
        "    # remove type information using keywords generated above\n",
        "    # remove meaningless connecting words like de, do, da, du\n",
        "    df[clean_name_final] = df[clean_name].str.title() \\\n",
        "        .str.replace('|'.join(type_keywords), '') \\\n",
        "        .str.replace('|'.join(abb_keywords), ' ') \\\n",
        "        .str.strip() \\\n",
        "        .str.replace('^de | de | de$|^de$|^do | do | do$|^do$|^da | da | da$|^da$|^du | du | du$|^du$ |^dos|^das',\n",
        "                     ' ', case=False) \\\n",
        "        .str.replace(\"  \", \" \") \\\n",
        "        .str.strip() \\\n",
        "        .str.title()\n",
        "\n",
        "def extract_type(df, clean_name, clean_name_final, extract_type):\n",
        "    '''\n",
        "    Remove type of a facility from a facility name, and puts type into a separate column\n",
        "                 #exp: Kayamba Centre de Sante >> Kayamba  ||  Centre de Sante\n",
        "    :param df: dataframe\n",
        "    :param clean_name: cleaned/standardized column name\n",
        "    :param clean_name_final: A column name that holds only name(no type)\n",
        "    :param extract_type: A column name that holds only type\n",
        "    :return: dataframe\n",
        "    '''\n",
        "    extract_types = []\n",
        "    df.clean_name.fillna(\"\", inplace=True)\n",
        "    df[clean_name_final].fillna(\"\", inplace=True)\n",
        "    for idx, row in df.iterrows():\n",
        "        name = row[clean_name].upper()\n",
        "        name_final = row[clean_name_final].upper()\n",
        "\n",
        "        # if clean_name_final is exactly the same as clean_name,\n",
        "        # this indicates no type information can be extracted, thus append NA\n",
        "        if name.upper() == name_final.upper():\n",
        "            extract_types.append(np.nan)\n",
        "\n",
        "        else:\n",
        "            name = OrderedSet(name.split())\n",
        "            name_final = OrderedSet(name_final.split())\n",
        "            # find the difference between two names\n",
        "            diff = ' '.join(list(name.difference(name_final)))\n",
        "            extract_types.append(diff.strip())\n",
        "\n",
        "    # remove de, do, da, du at start or end of extract_type\n",
        "    # replace empty string with NA\n",
        "    df[extract_type] = extract_types\n",
        "    df[extract_type] = df[extract_type].str.strip() \\\n",
        "        .str.replace(\"  \", \" \") \\\n",
        "        .str.replace('^de |^do |^da |^du | du$| de$| do$| da$|^de$|^do$|^da$|^du$', '', case=False) \\\n",
        "        .str.replace('^de |^do |^da |^du | du$| de$| do$| da$|^de$|^do$|^da$|^du$', '', case=False) \\\n",
        "        .str.strip() \\\n",
        "        .str.title() \\\n",
        "        .replace('', np.nan)\n",
        "    # replace empty string with NA\n",
        "    df[clean_name].replace('', np.nan, inplace=True)\n",
        "    df[clean_name_final].replace('', np.nan, inplace=True)\n",
        "\n",
        "def map_type(df, extract_type, sub_type, score, type_dict):\n",
        "    '''\n",
        "    Function=Use extract_type to map the type information extracted from the name column to one of the types in the type dictionary.\n",
        "    :param df: dataframe\n",
        "    :param extract_type: Type that extracted from name\n",
        "    :param sub_type: A column name to hold type\n",
        "    :param score: A column name to hold match score between extracted type and type dictionary\n",
        "    :param type_dict:  Country specific type dictionary\n",
        "    :return: dataframe\n",
        "    '''\n",
        "\n",
        "    types, abbrevs = type_dict['type'], type_dict['abbreviation']\n",
        "    sub_types = []\n",
        "    scores = []\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        # if extract_type is NA, just append NA\n",
        "        if not isinstance(row[extract_type], str):\n",
        "            sub_types.append(np.nan)\n",
        "            scores.append(np.nan)\n",
        "\n",
        "        # find best match\n",
        "        else:\n",
        "            match, match_score = process.extractOne(row[extract_type], list(types) + list(abbrevs),\n",
        "                                                    scorer=fuzz.ratio)\n",
        "\n",
        "            scores.append(match_score)\n",
        "            # if best match is abbreviation, map it to the corresponding type\n",
        "            if match in list(abbrevs):\n",
        "                match_type = type_dict[type_dict['abbreviation'] == match]['type'].iloc[0]\n",
        "                sub_types.append(match_type)\n",
        "            else:\n",
        "                sub_types.append(match)\n",
        "    df[sub_type] = sub_types\n",
        "    df[score] = scores\n",
        "\n",
        "def basic_checks(df, facility_name_clean, facility_type_clean):\n",
        "    '''\n",
        "    add four new column to input df to keep lenght of facility name, lenght of the type, if\n",
        "    facility name includes any special characters, and facility name with only numeric characters\n",
        "    :param df:\n",
        "    :return: add these columns to input df\n",
        "    hf_name_lenght: lenght of facility name, Too long (30>) and short (<3) name needs a closer look\n",
        "    hf_type_lenght: lenght of facility name, Too long (30>) and short (<3) name needs a closer look\n",
        "    has_special_chrs: list of the special character a facility name has\n",
        "    only_numeric: facilities with only numerical values\n",
        "    '''\n",
        "    df[\"hf_name_lenght\"] = \"\"\n",
        "    df[\"hf_type_lenght\"] = \"\"\n",
        "    df[\"special_chrs\"] = \"\"\n",
        "    df[\"only_numeric\"] = \"\"\n",
        "    df[facility_name_clean].fillna(\"\", inplace=True)\n",
        "    df[facility_type_clean].fillna(\"\", inplace=True)\n",
        "    for index, row in df.iterrows():\n",
        "        df.loc[index, \"hf_name_lenght\"] = len(row[facility_name_clean])\n",
        "        df.loc[index, \"hf_type_lenght\"] = len(row[facility_type_clean])\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        check_list = [\"?\", \"!\", \"//\", \"\\\\\", \"*\", \"!\", \"~\", \")\", \"(\", \"&\", \"$\", \"+\", \"^\", \"%\", \"√¥\", \"√à\",\"`\",\n",
        "                      \"√ßo\", \"√®\", \"√©\"]\n",
        "        for i in check_list:\n",
        "            if i in row[facility_name_clean]:\n",
        "                df.loc[index, \"special_chrs\"] = row[\"special_chrs\"] + \"\" + i\n",
        "\n",
        "        if row[facility_name_clean].isnumeric():\n",
        "            df.loc[index, \"only_numeric\"] = \"all_numerical\"\n",
        "\n",
        "\n",
        "\n",
        "### processing ###\n",
        "\n",
        "# read health facility table\n",
        "if health_facility_table.endswith(\".csv\"):  \n",
        "  hf_df=pd.read_csv(io.BytesIO(uploaded[health_facility_table])) \n",
        "elif health_facility_table.endswith(\".xlsx\") :  \n",
        "  hf_df=pd.read_excel(io.BytesIO(uploaded[health_facility_table])) \n",
        "\n",
        "# spelling dictionary table table\n",
        "if spelling_dictionary_table.endswith(\".csv\"):  \n",
        "  sd_df=pd.read_csv(io.BytesIO(uploaded[spelling_dictionary_table])) \n",
        "  sd_df=sd_df.drop_duplicates(['word', 'misspelling'])\n",
        "elif spelling_dictionary_table.endswith(\".xlsx\") :  \n",
        "  sd_df=pd.read_excel(io.BytesIO(uploaded[spelling_dictionary_table])) \n",
        "  sd_df=sd_df.drop_duplicates(['word', 'misspelling'])\n",
        "\n",
        "# type dictionary table table\n",
        "if type_dictionary_table.endswith(\".csv\"):  \n",
        "  td_df=pd.read_csv(io.BytesIO(uploaded[type_dictionary_table])) \n",
        "  td_df=td_df.drop_duplicates(['type'])\n",
        "elif type_dictionary_table.endswith(\".xlsx\") :  \n",
        "  td_df=pd.read_excel(io.BytesIO(uploaded[type_dictionary_table])) \n",
        "  td_df=td_df.drop_duplicates(['type'])\n",
        "\n",
        "\n",
        "preclean(hf_df, facility_name,\"clean_name\")\n",
        "correct_spelling(hf_df,sd_df, \"clean_name\" ,\"corrected_name\")\n",
        "remove_type_info(hf_df,td_df, \"corrected_name\", \"facility_name_short\")\n",
        "extract_type(hf_df, \"corrected_name\", \"facility_name_short\",\"extract_type\")\n",
        "map_type(hf_df ,\"extract_type\", \"sub_type\", \"score\", td_df)\n",
        "basic_checks(hf_df, \"facility_name_short\",\"sub_type\")\n",
        "hf_df.drop([\"clean_name\",\"corrected_name\"], inplace=True, axis=1, errors=\"ignore\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#export type_df\n",
        "output_table_name=health_facility_table.split(\".\")[0]+\"_cleaned.xlsx\"\n",
        "hf_df.to_excel(output_table_name)\n",
        "files.download(output_table_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "_KH2cFtccwOR",
        "outputId": "a7aec240-f23e-49d7-b509-332e9102b1e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-481d416aae21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    238\u001b[0m   \u001b[0mhf_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muploaded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhealth_facility_table\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0mhealth_facility_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".xlsx\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m   \u001b[0mhf_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muploaded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhealth_facility_table\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;31m# spelling dictionary table table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'eHealth_HFL_OpenAfrica_modified.xlsx'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part 5: Repeat for all datasets and combine into one file"
      ],
      "metadata": {
        "id": "pxEALiiW0-Hi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Repeat all steps for each health facility dataset you have explored in previous landscaping exercises. Upload the file after you have done a manual check as per the instructions above. Place the file in your country's health facilities folder on the Drive.\n",
        "\n"
      ],
      "metadata": {
        "id": "EHo4AUPi1P-U"
      }
    }
  ]
}